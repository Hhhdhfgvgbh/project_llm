version: 1
models_directory: "./models"
defaults:
  n_ctx: 8192
  n_gpu_layers: 0
  temperature: 0.7
  top_p: 0.95
  max_tokens: 1024
  threads: 8
models:
  phi:
    file: "Phi-3.5-mini-instruct-Q5_K_M.gguf"
    description: "Phi-3.5-mini-instruct-Q5_K_M"
    quantization: "Q5_K_M"
    required_for_base: true
    overrides:
      n_ctx: 16384
      n_gpu_layers: 35
  deepseek:
    file: "DeepSeek-R1-Distill-Llama-8B-Q5_K_M.gguf"
    description: "DeepSeek-R1-Distill-Llama-8B-Q5_K_M"
    quantization: "Q5_K_M"
    required_for_base: true
    overrides:
      n_ctx: 16384
      n_gpu_layers: 35
