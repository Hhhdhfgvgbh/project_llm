version: 1
base_pipeline:
  execution_mode: sequential
  stages:
    - id: stage1
      type: single
      model: llama3_q5
      system_prompt: "You are an expert analyst."
      generation:
        temperature: 0.6
      output_mode: question_and_answer

    - id: stage2
      type: single
      model: mistral_q4
      system_prompt: "Critique the previous answer."
      input_from: stage1
      output_mode: answer_only

    - id: stage3
      type: multi
      models:
        - llama3_q5
        - mistral_q4
      system_prompt: "Provide alternative interpretations."
      aggregation:
        type: synthesis
        synthesis_model: llama3_q5
      input_from: stage2
