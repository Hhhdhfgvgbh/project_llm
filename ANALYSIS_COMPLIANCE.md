# Аудит соответствия реализации документации

Проверены все файлы репозитория, включая `app/`, `config/`, `scripts/`, `tests/`, Docker/packaging-описания и документы `приложение план и блоки.txt` + `приложение ТЗ.txt`.

## Краткий итог

- **Базовая работоспособная архитектура действительно есть**: загрузка/валидация конфигов, реестр моделей, исполнение staged pipeline, агрегация, UI/CLI, сохранение сессий, базовые тесты.
- **Есть расхождения с README**: README всё ещё описывает `ModelWrapper` как mock-runtime, но в коде уже подключён реальный `llama_cpp.Llama`.
- **Есть расхождения с ТЗ**: manual builder, advanced resource management, persistent mode (LRU), обработка OOM/ошибок и replay/перезапуск стадий реализованы частично или отсутствуют.
- **Критичный практический момент**: тесты сейчас не проходят в «чистой» среде, потому что зависимость `llama_cpp` не добавлена в `pyproject.toml`.

## Сопоставление с «приложение план и блоки»

### Этап 1 (llama.cpp + CUDA / llama-cpp-python / single-model inference)
- **Частично/в прогрессе**.
- В коде есть прямой runtime на `llama_cpp.Llama`, методы load/generate/unload реализованы.
- Но `pyproject.toml` не содержит `llama-cpp-python`, из-за чего тестовый импорт падает в среде без ручной установки wheel.

### Этап 2 (Model Registry)
- **Реализовано**.
- Загрузка `models.yaml`, проверка файлов, фильтрация недоступных моделей и блокировка base-режима при отсутствии required models — есть.
- Отдельного logging-модуля нет, предупреждения хранятся в памяти и показываются в UI.

### Этап 3 (Resource Manager)
- **Частично**.
- Есть safety-коэффициенты RAM/VRAM и предзапусковая проверка.
- Нет реалистичной оценки под конкретные модели/контекст, нет расчёта комбинаций моделей и fallback-планировщика.

### Этап 4 (Model Wrapper)
- **Реализовано базово**.
- Методы `load()/unload()/generate()/estimate_memory()` присутствуют.
- Нет унифицированной обработки runtime-ошибок (например CUDA OOM) и graceful fallback внутри wrapper.

### Этап 5 (Pipeline Engine)
- **Частично**.
- Фиксированный `pipeline.yaml`, multi-stage, multi-model и агрегации работают.
- Ручной режим пока не является полноценным конструктором: в UI используется текущий pipeline как шаблон.

### Этап 6 (Aggregation Engine)
- **Реализовано**.
- Есть `concat`, `majority_vote`, `synthesis`, `custom_template`.

### Этап 7 (Session Manager)
- **Частично+**.
- Создание сессии, сохранение входа/конфига/выхода стадий, `final.txt`, список и загрузка истории — есть.
- Snapshot полной конфигурации как отдельный файл не сохраняется (частично покрыто `config_payload` per-stage).

### Этап 8 (Sequential Mode)
- **Реализовано**.
- На каждом шаге модель загружается, выполняется inference, затем выгружается.

### Этап 9 (Persistent Mode / cache / LRU)
- **Не реализовано**.
- Кеш моделей и LRU отсутствуют.

### Этап 10 (UI Streamlit: Base / Manual / History / Models)
- **Реализовано частично**.
- Все 4 вкладки есть, но Manual Builder пока без визуального конструктора стадий.

## Сопоставление с «приложение ТЗ»

- **Базовый пайплайн по конфигу** — реализован.
- **Блокировка base-mode при отсутствии обязательных моделей** — реализована.
- **Изменение порядка стадий/параметров через конфиг** — реализовано.
- **Несколько моделей на шаге + агрегации** — реализовано.
- **Manual mode работает при отсутствии base-required моделей** — концептуально да (нет проверки `base_mode_blocked` в manual executor), но при отсутствии конкретно выбранных моделей run завершится ошибкой.
- **Параметры generation в manual UI (temperature/top_p/max_tokens/n_ctx/n_gpu_layers)** — не реализовано в интерфейсе.
- **Проверка RAM/VRAM и sequential fallback** — проверка есть, fallback-стратегия отсутствует.
- **История сессий с промежуточными шагами** — реализовано в versioned формате.
- **Повторный запуск стадии из UI** — не реализован.
- **Надёжность (OOM/RAM fail handling без падений)** — частично; UI показывает exception, но спецобработки OOM нет.

## Дополнительные несоответствия/риски

1. **README устарел относительно runtime**
   - В README написано про mock `ModelWrapper`, но фактически уже идёт реальный импорт `llama_cpp`.

2. **Packaging gap**
   - Отсутствует зависимость `llama-cpp-python` в `pyproject.toml`, хотя модуль импортируется напрямую.

3. **Тесты и текущий runtime расходятся**
   - Тест `test_pipeline_execution.py` ожидает mock-строку (`"generated response"`), что не соответствует текущему реальному wrapper.

## Рекомендованный порядок доработок

1. Синхронизировать документацию и packaging:
   - Обновить README (убрать тезис про mock или сделать feature flag mock/runtime).
   - Добавить/нормализовать зависимость `llama-cpp-python` (или опциональный extra + fallback).

2. Стабилизировать тестирование:
   - В unit-тестах для pipeline использовать stub/mock wrapper через dependency injection.
   - Разделить unit-тесты (без реальной модели) и интеграционные (с реальной gguf).

3. Довести ТЗ-функции manual и reliability:
   - Visual manual stage-builder в UI.
   - Контролируемая обработка OOM + fallback execution path.
   - Перезапуск выбранной стадии и ветвление (parent/child run).

4. Реализовать persistent mode:
   - Кеш активных моделей, LRU-эвикция, предиктивная проверка памяти для multi-stage сценариев.
